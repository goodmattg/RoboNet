# example configuration file for training a set of video prediction model on baxter data from RoboNet
# each model is trained on a different set of cameras

# general experiment configurations

train_class: VPredTrainable 
max_steps: 300000
save_freq: 5000
batch_size: 8
train_fraction: 0.9
n_gpus: 4

# list of dictionaries containing data sources along with filter parameters
batch_config:
  # selects baxter data with autograsp enabled (adim=4, robot=baxter)
  - data_directory: ${DATA_DIR}
    robot: "sawyer"
    adim: 4

# loader_hparams used to initialize loader object
loader_hparams:
  dataset: "RoboNet"
  buffer_size: 10
  load_T: 15
  color_augmentation: 0.1
  cams_to_load: search/grid([[0, 1, 2],[1, 2, 3],[0, 2, 3], [0, 1, 3]])
  # cams_to_load: [0, 1, 2]  

# model_hparams used to create graph and loss function
model_hparams:
  model: deterministic
  graph_type: vgg_conv
  tv_weight: 0.0
